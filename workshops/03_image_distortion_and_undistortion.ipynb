{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "source": [
    "# 3: Image Distortion and Undistortion\n",
    "\n",
    "In the last [session](02_understanding_camera_models.ipynb) we looked at how we can use the camera matrix (K):\n",
    "\n",
    "$$K = \\left[\\begin{array}{ccc} f_x & 0 & c_x \\\\ 0 & f_y & c_y \\\\ 0 & 0 & 1 \\end{array}\\right]$$\n",
    "\n",
    "and the distortion coefficients (kc):\n",
    "\n",
    "- Radial distortion: $k_1$ to $k_6$\n",
    "- Tangential distortion: $p_1$ and $p_2$\n",
    "- Thin prism distortion: $s_1$ to $s_4$\n",
    "- Tilt distortion: $\\tau_x$ and $\\tau_y$\n",
    "\n",
    "to model a camera, and how we can use this model to move between image (2D) space and world (3D) space:\n",
    "\n",
    "::::{margin}\n",
    ":::{warning}\n",
    "When we do normalizations and distortions we usually omit the 3rd dimension, keeping only:\n",
    "\n",
    "$$\\left[\\begin{array}{cc} x^* \\\\ y^*\\end{array}\\right]$$\n",
    "\n",
    "This is because the 3rd dimension is always 1, but it's important that we remember that it's there.\n",
    ":::\n",
    "::::\n",
    "\n",
    "$$\n",
    "\\left[\\begin{array}{cc} x \\\\ y \\end{array}\\right] \\xrightarrow[K]{\\mathrm{normalize}}\n",
    "\\left[\\begin{array}{cc} x' \\\\ y' \\\\ 1\\end{array}\\right] \\xrightarrow[kc]{\\mathrm{distort}}\n",
    "\\left[\\begin{array}{cc} x^* \\\\ y^* \\\\ 1\\end{array}\\right]\n",
    "$$\n",
    "\n",
    "In this session we will look at how we can undistort instead of distorting. The reality is that when we want to work on 3D cameras, the images are already distorted. We want to undistort them to get the correct vectors:\n",
    "\n",
    "$$\n",
    "\\left[\\begin{array}{cc} x \\\\ y \\end{array}\\right] \\xrightarrow[K]{\\mathrm{normalize}}\n",
    "\\left[\\begin{array}{cc} x' \\\\ y' \\\\ 1\\end{array}\\right] \\xrightarrow[kc]{\\mathrm{undistort}}\n",
    "\\left[\\begin{array}{cc} x'' \\\\ y'' \\\\ 1\\end{array}\\right]\n",
    "$$\n",
    "\n",
    "Before we start I want to show an example of why this is important, during projections. We will look more at projection in the next session, but for now let's look at a simple example. Assume you have a 3D coordinate:\n",
    "\n",
    "$$\\left[\\begin{array}{cc} X \\\\ Y \\\\ Z \\end{array}\\right]$$\n",
    "\n",
    "How can we figure out where this point would be seen in the image? We now actually have a straight forward approach:\n",
    "\n",
    "$$\n",
    "\\left[\\begin{array}{cc} X \\\\ Y \\\\ Z \\end{array}\\right] \\xrightarrow[Z]{\\mathrm{divide}}\n",
    "\\left[\\begin{array}{cc} \\frac{X}{Z} \\\\ \\frac{Y}{Z} \\\\ 1\\end{array}\\right] \\xrightarrow[kc]{\\mathrm{distort}}\n",
    "\\left[\\begin{array}{cc} x' \\\\ y' \\\\ 1\\end{array}\\right] \\xrightarrow[K]{\\mathrm{denormalize}}\n",
    "\\left[\\begin{array}{cc} x \\\\ y\\end{array}\\right]\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    ":::{note}\n",
    "OpenCV uses the following order for the distortion coefficients: \n",
    "\n",
    "kc = [$k_1$, $k_2$, $p_1$, $p_2$[, $k_3$[, $k_4$, $k_5$, $k_6$[, $s_1$, $s_2$, $s_3$, $s_4$[, $\\tau_x$, $\\tau_y$]]]]]\n",
    "\n",
    "Be careful about this if you want to use OpenCV functions.\n",
    ":::\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Undistortion\n",
    "\n",
    "Going back to the 5 parameter model we looked at in [session 2](02_understanding_camera_models.ipynb), we can see that the distortion is a function of the normalized pixel coordinates:\n",
    "\n",
    "$$\\begin{align*} x_d &= x(1 + k_1 r^2 + k_2 r^4 + k_3 r^6) + 2p_1 x y + p_2(r^2 + 2x^2) \\\\ y_d &= y(1 + k_1 r^2 + k_2 r^4 + k_3 r^6) + p_1(r^2 + 2y^2) + 2p_2 x y \\end{align*}$$\n",
    "\n",
    "where $r^2 = x^2 + y^2$, and $x$ and $y$ are the normalized pixel coordinates. We can see that the distortion is a function of the normalized pixel coordinates, and that the distortion is a non-linear function of the pixel coordinates. This means that we can not simply invert the distortion function to get the undistorted pixel coordinates. Instead we need to find a different way to undistort the image.\n",
    "\n",
    "Let's first create a reference grid of pixel values and a reference [lens model](../oaf_vision_3d/lens_model.py). We plot the resulting grid:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from oaf_vision_3d.lens_model import CameraMatrix, DistortionCoefficients, LensModel\n",
    "\n",
    "\n",
    "lens_model = LensModel(\n",
    "    camera_matrix=CameraMatrix(\n",
    "        fx=2500.0,\n",
    "        fy=2500.0,\n",
    "        cx=1250.0,\n",
    "        cy=1000.0,\n",
    "    ),\n",
    "    distortion_coefficients=DistortionCoefficients(\n",
    "        k1=0.3,\n",
    "        k2=-0.1,\n",
    "        p1=-0.02,\n",
    "    ),\n",
    ")\n",
    "\n",
    "reference_pixels_grid = np.stack(\n",
    "    np.meshgrid(\n",
    "        np.linspace(0, 2499, 11),\n",
    "        np.linspace(0, 1999, 9),\n",
    "    ),\n",
    "    axis=-1,\n",
    "    dtype=np.float32,\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(8, 10))\n",
    "plt.plot(reference_pixels_grid[..., 0], reference_pixels_grid[..., 1], \"-r\")\n",
    "plt.plot(reference_pixels_grid[..., 0].T, reference_pixels_grid[..., 1].T, \"-r\")\n",
    "plt.axis(\"image\")\n",
    "plt.axis(\"off\")\n",
    "plt.xlim(-500, 3000)\n",
    "plt.ylim(-500, 2500)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we can use the distortion function to distort the grid. We plot the distorted grid on top of the reference grid:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "pixels_grid = lens_model.denormalize_pixels(\n",
    "    lens_model.distort_pixels(lens_model.normalize_pixels(reference_pixels_grid))\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(8, 10))\n",
    "plt.plot(reference_pixels_grid[..., 0], reference_pixels_grid[..., 1], \"-r\")\n",
    "plt.plot(reference_pixels_grid[..., 0].T, reference_pixels_grid[..., 1].T, \"-r\")\n",
    "plt.plot(pixels_grid[..., 0], pixels_grid[..., 1], \"-b\")\n",
    "plt.plot(pixels_grid[..., 0].T, pixels_grid[..., 1].T, \"-b\")\n",
    "plt.axis(\"image\")\n",
    "plt.axis(\"off\")\n",
    "plt.xlim(-500, 3000)\n",
    "plt.ylim(-500, 2500)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our goal is to undistort the distorted grid. The result should be a grid that looks like the reference grid, of course we do not know the reference grid to compare with in normal cases. \n",
    "\n",
    "First, instead of plotting the grid, let's plot the change between the distorted and the reference grid. This will give us an idea of how the distortion looks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "pixel_vector = pixels_grid - reference_pixels_grid\n",
    "\n",
    "plt.figure(figsize=(8, 10))\n",
    "plt.quiver(\n",
    "    reference_pixels_grid[..., 0],\n",
    "    reference_pixels_grid[..., 1],\n",
    "    pixel_vector[..., 0],\n",
    "    pixel_vector[..., 1],\n",
    "    scale_units=\"xy\",\n",
    "    scale=1,\n",
    "    color=\"r\",\n",
    ")\n",
    "plt.axis(\"image\")\n",
    "plt.axis(\"off\")\n",
    "plt.xlim(-500, 3000)\n",
    "plt.ylim(-500, 2500)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we have no way of directly undistorting, what happens if we just distort again?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "distorted_pixels_grid = lens_model.denormalize_pixels(\n",
    "    lens_model.distort_pixels(lens_model.normalize_pixels(pixels_grid))\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(8, 10))\n",
    "plt.plot(reference_pixels_grid[..., 0], reference_pixels_grid[..., 1], \"-r\")\n",
    "plt.plot(reference_pixels_grid[..., 0].T, reference_pixels_grid[..., 1].T, \"-r\")\n",
    "plt.plot(pixels_grid[..., 0], pixels_grid[..., 1], \"-b\")\n",
    "plt.plot(pixels_grid[..., 0].T, pixels_grid[..., 1].T, \"-b\")\n",
    "plt.plot(distorted_pixels_grid[..., 0], distorted_pixels_grid[..., 1], \"-g\")\n",
    "plt.plot(distorted_pixels_grid[..., 0].T, distorted_pixels_grid[..., 1].T, \"-g\")\n",
    "plt.axis(\"image\")\n",
    "plt.axis(\"off\")\n",
    "plt.xlim(-500, 3000)\n",
    "plt.ylim(-500, 2500)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we expect, it becomes even more distorted. Let's also take alook at quiver plot for both the distorted and the double distorted grid:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "distorted_pixel_vector = distorted_pixels_grid - pixels_grid\n",
    "\n",
    "plt.figure(figsize=(8, 10))\n",
    "plt.quiver(\n",
    "    reference_pixels_grid[..., 0],\n",
    "    reference_pixels_grid[..., 1],\n",
    "    pixel_vector[..., 0],\n",
    "    pixel_vector[..., 1],\n",
    "    scale_units=\"xy\",\n",
    "    scale=1,\n",
    "    color=\"r\",\n",
    ")\n",
    "plt.quiver(\n",
    "    pixels_grid[..., 0],\n",
    "    pixels_grid[..., 1],\n",
    "    distorted_pixel_vector[..., 0],\n",
    "    distorted_pixel_vector[..., 1],\n",
    "    scale_units=\"xy\",\n",
    "    scale=1,\n",
    "    color=\"b\",\n",
    ")\n",
    "plt.axis(\"image\")\n",
    "plt.axis(\"off\")\n",
    "plt.xlim(-500, 3000)\n",
    "plt.ylim(-500, 2500)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's interesting! The change between the distorted and the double distorted grid is not the same as the change between the distorted and the reference grid, but it is close. What happens if we flip the arrows?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "next_pixel_grid = pixels_grid + pixel_vector\n",
    "\n",
    "plt.figure(figsize=(8, 10))\n",
    "plt.quiver(\n",
    "    pixels_grid[..., 0],\n",
    "    pixels_grid[..., 1],\n",
    "    pixel_vector[..., 0],\n",
    "    pixel_vector[..., 1],\n",
    "    scale_units=\"xy\",\n",
    "    scale=1,\n",
    "    color=\"r\",\n",
    ")\n",
    "plt.quiver(\n",
    "    next_pixel_grid[..., 0],\n",
    "    next_pixel_grid[..., 1],\n",
    "    -distorted_pixel_vector[..., 0],\n",
    "    -distorted_pixel_vector[..., 1],\n",
    "    scale_units=\"xy\",\n",
    "    scale=1,\n",
    "    color=\"b\",\n",
    "    width=0.004,\n",
    ")\n",
    "plt.axis(\"image\")\n",
    "plt.axis(\"off\")\n",
    "plt.xlim(-500, 3000)\n",
    "plt.ylim(-500, 2500)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are not where we want to be, but we are closer. Let's also look at the grids:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "next_undistorted_pixel_grid = pixels_grid - distorted_pixel_vector\n",
    "\n",
    "plt.figure(figsize=(8, 10))\n",
    "plt.plot(reference_pixels_grid[..., 0], reference_pixels_grid[..., 1], \"r-\")\n",
    "plt.plot(reference_pixels_grid[..., 0].T, reference_pixels_grid[..., 1].T, \"r-\")\n",
    "plt.plot(pixels_grid[..., 0], pixels_grid[..., 1], \"b-\")\n",
    "plt.plot(pixels_grid[..., 0].T, pixels_grid[..., 1].T, \"b-\")\n",
    "plt.plot(next_undistorted_pixel_grid[..., 0], next_undistorted_pixel_grid[..., 1], \"g-\")\n",
    "plt.plot(\n",
    "    next_undistorted_pixel_grid[..., 0].T, next_undistorted_pixel_grid[..., 1].T, \"g-\"\n",
    ")\n",
    "\n",
    "plt.axis(\"image\")\n",
    "plt.axis(\"off\")\n",
    "plt.xlim(-500, 3000)\n",
    "plt.ylim(-500, 2500)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You might already have guessed it, this is an iterative process. We can keep iterating until we are happy with the result. Let's do this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "from ipywidgets import interact, IntSlider\n",
    "\n",
    "normalized_pixels = lens_model.normalize_pixels(pixels_grid)\n",
    "undistorted_normalized_pixels = normalized_pixels.copy()\n",
    "\n",
    "iterations = 10\n",
    "iteration_results, errors = [pixels_grid], [\n",
    "    np.sqrt(np.mean((pixels_grid - reference_pixels_grid) ** 2))\n",
    "]\n",
    "for _ in range(iterations):\n",
    "    undistorted_normalized_pixels += normalized_pixels - lens_model.distort_pixels(\n",
    "        undistorted_normalized_pixels\n",
    "    )\n",
    "    undistorted_pixels = lens_model.denormalize_pixels(\n",
    "        undistorted_normalized_pixels.copy()\n",
    "    )\n",
    "    iteration_results.append(undistorted_pixels)\n",
    "    errors.append(np.sqrt(np.mean((undistorted_pixels - reference_pixels_grid) ** 2)))\n",
    "\n",
    "\n",
    "def plot_with_sliders(iteration: int) -> None:\n",
    "    new_pixels_grid = iteration_results[iteration]\n",
    "    error = errors[iteration]\n",
    "\n",
    "    plt.figure(figsize=(8, 10))\n",
    "    plt.plot(reference_pixels_grid[..., 0], reference_pixels_grid[..., 1], \"-r\")\n",
    "    plt.plot(reference_pixels_grid[..., 0].T, reference_pixels_grid[..., 1].T, \"-r\")\n",
    "    plt.plot(new_pixels_grid[..., 0], new_pixels_grid[..., 1], \"-b\")\n",
    "    plt.plot(new_pixels_grid[..., 0].T, new_pixels_grid[..., 1].T, \"-b\")\n",
    "    plt.axis(\"image\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.xlim(-500, 2999)\n",
    "    plt.ylim(2499, -500)\n",
    "    plt.title(f\"Curren RMS: {error:.03f} pixels\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "_ = interact(\n",
    "    plot_with_sliders, iteration=IntSlider(min=0, max=iterations, step=1, value=0)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "plt.plot(np.arange(iterations + 1), errors, \"-r\")\n",
    "plt.yscale(\"log\")\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"RMS error (pixels)\")\n",
    "plt.grid()\n",
    "plt.title(\"Convergence of the iterative undistortion\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That was actually pretty straight forward, but what have we actually done? Let's define the different naming first:\n",
    "\n",
    "- $x'$ and $y'$ are the normalized pixel coordinates, these coordinates are distorted since an image is \"always\" distorted.\n",
    "- $x''$ and $y''$ are the undistorted normalized pixel coordinates, these are the coordinates we want to find.\n",
    "- If we distort $x''$ and $y''$ we get $x'$ and $y'$.\n",
    "\n",
    "We are now estimating that:\n",
    "\n",
    "$$\n",
    "\\left[\\begin{array}{cc} x'' \\\\ y'' \\end{array}\\right] - \\left[\\begin{array}{cc} x' \\\\ y' \\end{array}\\right] \\approx\n",
    "\\left[\\begin{array}{cc} x' \\\\ y' \\end{array}\\right] - \\text{distort}\\left(\\left[\\begin{array}{cc} x' \\\\ y' \\end{array}\\right]\\right)\n",
    "$$\n",
    "\n",
    "To make it iterative we have to add som indices:\n",
    "\n",
    "$$\n",
    "\\left[\\begin{array}{cc} x''_n \\\\ y''_n \\end{array}\\right] - \\left[\\begin{array}{cc} x''_{n-1} \\\\ y''_{n-1} \\end{array}\\right] \\approx\n",
    "\\left[\\begin{array}{cc} x''_0 \\\\ y''_0 \\end{array}\\right] - \\text{distort}\\left(\\left[\\begin{array}{cc} x''_{n-1} \\\\ y''_{n-1} \\end{array}\\right]\\right)\n",
    "$$\n",
    "\n",
    "and we choose the initial guess to $x''_0 = x'$ and $y''_0 = y'$. This gives us the following iterative process:\n",
    "\n",
    "$$\n",
    "\\left[\\begin{array}{cc} x''_n \\\\ y''_n \\end{array}\\right] = \\left[\\begin{array}{cc} x''_{n-1} \\\\ y''_{n-1} \\end{array}\\right] + \\left[\\begin{array}{cc} x''_0 \\\\ y''_0 \\end{array}\\right] - \\text{distort}\\left(\\left[\\begin{array}{cc} x''_{n-1} \\\\ y''_{n-1} \\end{array}\\right]\\right)\n",
    "$$\n",
    "\n",
    "We can simplify this down to a simple equation:\n",
    "\n",
    "$$\n",
    "P_n = P_{n-1} + P_0 - \\text{distort}(P_{n-1})\n",
    "$$\n",
    "\n",
    "where $P = [x, y]$ is the pixel coordinates and $P_0 = [x', y']$ is our initial guess. Let's implement this in a function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nptyping import Float32, NDArray, Shape\n",
    "\n",
    "from oaf_vision_3d.lens_model import _distort_pixels as distort_pixels\n",
    "\n",
    "\n",
    "def undistort_pixels(\n",
    "    normalized_pixels: NDArray[Shape[\"H, W, 2\"], Float32],\n",
    "    distortion_coefficients: DistortionCoefficients,\n",
    "    number_of_iterations: int = 10,\n",
    ") -> NDArray[Shape[\"H, W, 2\"], Float32]:\n",
    "    undistorted_normalized_pixels = normalized_pixels.copy()\n",
    "    for _ in range(number_of_iterations):\n",
    "        undistorted_normalized_pixels += normalized_pixels - distort_pixels(\n",
    "            normalized_pixels=undistorted_normalized_pixels,\n",
    "            distortion_coefficients=distortion_coefficients,\n",
    "        )\n",
    "    return undistorted_normalized_pixels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{note}\n",
    "Itâ€™s reasonable to ask: \"If we want undistorted pixels, why are the models written from undistorted to distorted?\" In practice, projections often work in reverse to address key problems. However, there are models designed the other way around (e.g., Halcon).\n",
    ":::\n",
    "\n",
    "## Creating an undistorted image\n",
    "\n",
    "Now we can look at how we undistort an image, that is, if you have a distorted image like this:\n",
    "\n",
    "![distorted](../test_data/checkerboard.png)\n",
    "\n",
    "How can we undistort it to get this:\n",
    "\n",
    "![undistorted](../test_data/undistorted_checkerboard.png)\n",
    "\n",
    "Let's start by loading the image and the camera model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "from oaf_vision_3d._test_data_paths import TestDataPaths\n",
    "\n",
    "image = plt.imread(str(TestDataPaths.distorted_checkerboard))\n",
    "lens_model = LensModel.read_from_json(TestDataPaths.distorted_checkerboard_lens_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is all we need to undistort the image, remember that the [lens model](../oaf_vision_3d/lens_model.py) has classmethods for normalizations and distortions. If we undistort the pixel index we get where that pixel should have been. Sadly this does not help us, since we cannot make an image with float value indices (this is what you do in a pointcloud). Instead we need to create a perfect pixel grid and distort it, this will tell us where in the image we are looking. We can then interpolate the pixel values to get the undistorted image. The step-by-step process is:\n",
    "\n",
    "1. Create a perfect pixel grid. (Hint: `np.indices`)\n",
    "2. Distort the pixel grid. (Hint: `normalize` -> `distort` -> `denormalize`)\n",
    "3. Interpolate the pixel values. (Hint: `scipy.ndimage.map_coordinates`)\n",
    "\n",
    "The resulting image should be the undistorted image. Let's implement this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage import map_coordinates\n",
    "\n",
    "\n",
    "def undistort_image(\n",
    "    image: NDArray[Shape[\"H, W, 3\"], Float32], lens_model: LensModel\n",
    ") -> NDArray[Shape[\"H, W, 3\"], Float32]:\n",
    "    y, x = np.indices(image.shape[:2])\n",
    "    pixels = np.stack([x, y], axis=-1)\n",
    "    normalized_pixels = lens_model.normalize_pixels(pixels=pixels)\n",
    "    distorted_normalized_pixels = lens_model.distort_pixels(\n",
    "        normalized_pixels=normalized_pixels\n",
    "    )\n",
    "    distorted_pixels = lens_model.denormalize_pixels(pixels=distorted_normalized_pixels)\n",
    "\n",
    "    undistorted_image = np.stack(\n",
    "        [\n",
    "            map_coordinates(\n",
    "                input=_image,\n",
    "                coordinates=[distorted_pixels[..., 1], distorted_pixels[..., 0]],\n",
    "                order=1,\n",
    "            )\n",
    "            for _image in image.transpose(2, 0, 1)\n",
    "        ],\n",
    "        axis=-1,\n",
    "    )\n",
    "    return undistorted_image.astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if it works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "undistorted_image = undistort_image(image=image, lens_model=lens_model)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.imshow(undistorted_image)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New camera matrix\n",
    "\n",
    "When we undistort an image also change what is visible in the image. In the image above we have actually cropped away all the white around the checkerboard. In this case it is not a problem, but what if there are information that we want to keep? Let's take a look at the following image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "image_house = plt.imread(str(TestDataPaths.distorted_house))\n",
    "lens_model_house = LensModel.read_from_json(TestDataPaths.distorted_house_lens_model)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.imshow(image_house)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we undistort the image we get:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "undistorted_image_house = undistort_image(\n",
    "    image=image_house, lens_model=lens_model_house\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.imshow(undistorted_image_house)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll leave it up to you to solve this problem, but I'll give you a hint. The camera matrix is the key to this problem, and you can use the camera matrix to change the size of the image. But be careful, you should only change the camera matrix on the normalization step, not the denormalization step. OpenCV has a function for this, `cv2.getOptimalNewCameraMatrix` that you could look into, but you still need to implement the logic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from oaf_vision_3d.lens_model import normalize_pixels\n",
    "\n",
    "\n",
    "def undistort_image_with_new_camera_matrix(\n",
    "    image: NDArray[Shape[\"H, W, 3\"], Float32],\n",
    "    lens_model: LensModel,\n",
    "    new_camera_matrix: CameraMatrix,\n",
    ") -> NDArray[Shape[\"H, W, 3\"], Float32]: ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = 1.0\n",
    "new_camera_matrix = CameraMatrix(\n",
    "    fx=lens_model_house.camera_matrix.fx * scale,\n",
    "    fy=lens_model_house.camera_matrix.fy * scale,\n",
    "    cx=lens_model_house.camera_matrix.cx,\n",
    "    cy=lens_model_house.camera_matrix.cy,\n",
    ")\n",
    "\n",
    "new_undistorted_image_house = undistort_image_with_new_camera_matrix(\n",
    "    image=image_house, lens_model=lens_model_house, new_camera_matrix=new_camera_matrix\n",
    ")\n",
    "\n",
    "if new_undistorted_image_house is not None:\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.imshow(new_undistorted_image_house)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "\n",
    "new_camera_matrix, _ = cv2.getOptimalNewCameraMatrix(\n",
    "    cameraMatrix=lens_model_house.camera_matrix.as_matrix(),\n",
    "    distCoeffs=lens_model_house.distortion_coefficients.as_opencv_vector(),\n",
    "    imageSize=image_house.shape[:2][::-1],\n",
    "    alpha=0,\n",
    ")\n",
    "\n",
    "new_undistorted_image_house = undistort_image_with_new_camera_matrix(\n",
    "    image=image_house,\n",
    "    lens_model=lens_model_house,\n",
    "    new_camera_matrix=CameraMatrix.from_matrix(\n",
    "        np.array(new_camera_matrix, dtype=np.float32)\n",
    "    ),\n",
    ")\n",
    "\n",
    "if new_undistorted_image_house is not None:\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.imshow(new_undistorted_image_house)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.11.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
